services:
  data-fetcher:
    build:
      context: ./data-fetcher
      dockerfile: Dockerfile
    networks:
      - predpump-network
      - default  # Allow access to external APIs
    restart: on-failure
    environment:
      - KAFKA_BROKERS=kafka:9092
      - CH_DSN=clickhouse://app:app_password@clickhouse:9000/default?dial_timeout=5s&max_execution_time=60
      - DATA_FETCHER_PORT=8083
    depends_on:
      kafka:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    command: ["/bin/sh", "-c", "sleep 5 && /app/data-fetcher"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/healthz"]
      interval: 15s
      timeout: 5s
      retries: 8
      start_period: 30s
    # Memory limit: 256MB
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
  analytics-engine:
    build:
      context: ./analytics-engine
      dockerfile: Dockerfile
    networks:
      - predpump-network
    restart: on-failure
    environment:
      - KAFKA_BROKERS=kafka:9092
      - CH_DSN=clickhouse://app:app_password@clickhouse:9000/default?dial_timeout=5s&max_execution_time=60
      - CONFIDENCE_THRESHOLD=0.10
      - ML_MIN_CANDLES_BOOTSTRAP=20
      - ML_MIN_CANDLES=60
      - ANALYTICS_ENGINE_PORT=8081
    depends_on:
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    ports:
      - "8081:8081"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/healthz"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    # Memory limit: 512MB (ML model training requires more memory)
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
  api-gateway:
    build:
      context: .
      dockerfile: api-gateway/Dockerfile
    networks:
      - predpump-network
    restart: on-failure
    ports:
      - "8080:8080"
    environment:
      - KAFKA_BROKERS=kafka:9092
      - ANALYTICS_ENGINE_URL=http://analytics-engine:8081
      - API_GATEWAY_PORT=8080
    depends_on:
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      analytics-engine:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 15s
      timeout: 5s
      retries: 8
      start_period: 30s
    # Memory limit: 256MB
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    networks:
      - predpump-network
    restart: on-failure
    ports:
      - "3000:80"
    environment:
      - VITE_API_URL=http://api-gateway:8080
    depends_on:
      - api-gateway
    # Memory limit: 128MB
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
  redis:
    image: redis:7-alpine
    networks:
      - predpump-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    # Memory limit: 256MB
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
  clickhouse:
    image: clickhouse/clickhouse-server:24.8
    networks:
      - predpump-network
    environment:
      - CLICKHOUSE_DB=default
      - CLICKHOUSE_USER=app
      - CLICKHOUSE_PASSWORD=app_password
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    networks:
      - predpump-network
    restart: on-failure
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_HEAP_OPTS: -Xmx512M -Xms256M
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_ZOOKEEPER_SET_ACL: 'false'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_CREATE_TOPICS: "candle_1m:1:1,direction_signals:1:1,orderbook:1:1,trades:1:1"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_AUTO_LEADER_REBALANCE_ENABLE: 'true'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      # Additional settings to ensure topics are created
      KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE: 'false'
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 20
      start_period: 180s  # Increased start period to allow more time for zookeeper to be ready
    # Memory limit: 1GB (Kafka requires significant memory for buffering)
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    volumes:
      - kafka_data:/var/lib/kafka/data

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    networks:
      - predpump-network
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_HEAP_OPTS: -Xmx512M -Xms256M
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_MAX_CLIENT_CNXNS: 0  # Allow unlimited connections
      ZOOKEEPER_AUTOPURGE_SNAPRETAINCOUNT: 3
      ZOOKEEPER_AUTOPURGE_PURGEINTERVAL: 0
    # NOTE: Skipping healthcheck for zookeeper to avoid issues with /dev/tcp and timeout in alpine container
    healthcheck:
      test: ["CMD", "bash", "-c", "echo ruok | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    # Memory limit: 512MB
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data

networks:
  predpump-network:
    driver: bridge

volumes:
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  clickhouse_data:
    driver: local
